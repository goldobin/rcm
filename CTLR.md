# RCM Controller

## Purpose

Currently two problems exist:

- The first problem is process management in platform independent way.  
  
- The second problem is server log aggregation. RCM should has possibility to get logs from each redis node and merge 
them together to show the complete picture of server behaviour. This way the order of events in consolidated log should 
be the order of actual event appearance.

## Discussion

Managing processes in platform independent way is not simple task. Each platform has nuances which can't be uniformly 
addressed. Right now only PID-file based process management is implemented. This strategy is platform independent but
does not fit well when you starting to stress the cluster: `kill -9` or hardware server crash will not delete pid file 
and there is no platform independent way to check if process with corresponding PID is still running. This way RCM will 
has stale information about real cluster nodes state. 

Two sources of node logs exist: FILE and STDOUT. Let's discuss each of them. 

Each log file generated by `redis-server` can be *tailed* and the outputs can be merged so when line is added to the log 
file of the node it appears on consolidated log. It looks like simple solution. But actually it is not out of the box 
solution for Go. Actually there are 2 solutions exist. The first one is to execute external `tail -f` process and 
collect process `stdout`. The second one is to use Go IO utilities. But the problem that you can't simply tell the input 
stream ignore EOF and wait when something will be written in the file. It was not intended to be used this way. Third 
party libraries utilize some pooling strategy (like check for the lines added in 1 second) or subscribe for asynchronous 
file size change event (`inotify` in Linux). 

Both two FILE based solutions has disadvantages. The first solutions should execute external process and manage it. And 
the case when somebody can kill the process should not be forgotten. The second one also has some conner cases like file 
can be deleted or moved and appeared again so file descriptor will be changed or content of the file can be changed and 
the correct offset to the end of the file will be lost. 

The STDOUT can be configured in `redis-server` and easily collected if you are the parent of the executed `redis-server` 
process. This solution does not has disadvantages which FILE-based has. The parent process just consuming events as an 
input stream. Right now RCM is actually executing `redis-server` processes. But because RCM is an utility it executing 
process in daemon mode and terminates right after that. So it can't consume stdout of `redis-server` process.

## Solution

The solution which can solve both problems considering discussed possible approaches is to run external process which 
will execute and manage `redis-server` processes in non daemon mode, consume STDOUT logs from them and produce 
aggregated logs on-demand to the main RCM utility.

This approach will give full control of `redis-server` processes in platform independent way because only Go's 
`os/exec` API will be utilized. No need to exec external `kill` utility or read PID file. The parent/child process 
hierarchy rules also gives this solution advantage: if controller process is running RCM utility can query for running 
`redis-server` processes if controller is not answering for queries it means that controller is stopped thus there are 
no running `redis-server` processes. So RCM utility has clear picture of the cluster.   

For logs aggregation proposed approach will do well. The same Go's `os/exec` API will be used and logs will be consumed 
by reading STDOUT of `redis-server` process. There is no need to deal with external log file change, FS events or file 
change pooling.

As soon as RCM controller will be an external background process RCM utility can communicate with it using one of 
interprocess communication techniques. The simples and relatively quick solution is to expose REST based API. REST 
is widely adopted and has good support of libraries. The payload format can be JSON or YAML as quickest solution. 

Why not Protobuf? Protobuf shines when you need to achieve minimal payload footprint. But for RCM it can't be 
considered as a significant advantage. And you need to pass additional steps like install `go` plugin for `protoc`, 
generate code, convert structs to protobuf DTO. JSON/YAML in this case are much easier to use.

## API Draft

### Retrieve nodes
`GET  /nodes` - Retrieve running nodes.

#### Response

```
Status: 200 OK
```
---
```
[ 
    {
        "id": 9001,
        "ip": "127.0.0.1",
        "port": 9001,
        "pid": 2871,
        "persistence": false,
        "state": "RUNNING"
    }, {
        "id": 9002,
        "ip": "127.0.0.1",
        "port": 9002,
        "pid": 2874,
        "persistence": false,
        "state": "RUNNING"
    }
]
```

### Create new node

`POST /nodes`

#### Input

```json
{ 
    "port": "9001",
    "persistence": false 
}
```

#### Response

```
Status: 201 Created
Location: http://localhost:28080/nodes/9001
```
---
```
{
    "id": 9001,
    "ip": "127.0.0.1",
    "port": 9001,
    "pid": 2871,
    "persistence": false,
    "state": "RUNNING"
}
```

### Remove node

`DELETE /nodes/{id}`

#### Response

```
Status: 204 No Content
```

### Start/Stop node

`PUT /nodes/{id}/state` 


#### Input

Possible state values are `RUNNING` | `NOT_RUNNING`. Node can be killed by specifying additional header 
`X-Term-Signal: TERM | KILL`

```
X-Term-Signal:KILL
```
---
```json
{ 
    "state": "NOT_RUNNING"
}
```

#### Response

```
Status: 200 OK
```
---
```json
{ 
    "state": "NOT_RUNNING"
}
```

### Retrieve node logs

`GET  /nodes/{port}/logs` - Retrieve log for the node. WebSocket based stream of logging events for node. 

#### Request 

```
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Protocol: json-stream-logs
```

#### Response

```
HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Protocol: json-stream-logs
```
---
```
{
    "@timestamp":"2016-01-04T10:45:54.335+00:00",
    "message":"WARNING you have Transparent Huge Pages (THP) support enabled in your kernel..."    
}\n
{
    "@timestamp":"2016-01-04T10:45:54.336+00:00",
    "message":"The server is now ready to accept connections on port 6379"
}\n
```
